{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b32343",
   "metadata": {},
   "source": [
    "# AudeyART\n",
    "\n",
    "This notebook implements a basic version of FuzzyART and tests it out on the relatively \"simple\" Iris dataset.\n",
    "\n",
    "FuzzyART is by default an unsupervised learning algorithm (a.k.a. clustering), so this file demonstrates how to cluster the Iris dataset with it.\n",
    "Future experiments and scripts will show how to do so in a supervised way so that train/test accuracy can be computed.\n",
    "\n",
    "For now, we will see if a \"standard\" FuzzyART module can identify some natural structures/clusters in the Iris data without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85dd347",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "First, we load all of our dependencies for the notebook.\n",
    "Be sure to be working in an activated virtual environment with the requirements installed with\n",
    "\n",
    "```shell\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "More about this in the <a href=README.md> <tt>README.md</tt></a> file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDLIB IMPORTS\n",
    "\n",
    "# For manipulating local paths in an object-oriented way\n",
    "from pathlib import Path\n",
    "\n",
    "# 3RD PARTY IMPORTS\n",
    "\n",
    "# The PyTorch library containing neural network utilities and the Tensor datatype\n",
    "import torch\n",
    "# A convenient import of Tensor so that we don't have to write torch.Tensor every time\n",
    "from torch import Tensor\n",
    "# Pandas for loading and manipulating data as a DataFrame\n",
    "import pandas as pd\n",
    "# Numpy for handling numpy arrays (i.e., matplotlib doesn't understand Tensor types, but it does know numpy.nparray)\n",
    "import numpy as np\n",
    "# A sklearn utility for handling normalization of data automatically\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# From scikit-learn, for casting the data to 2D for visualization.\n",
    "# This is not how the data actually looks in 4D, but the best that we can do is to cast it to 2D such that relative distances are mostly maintained.\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# The most common way of importing matplotlib for plotting in Python\n",
    "from matplotlib import pyplot as plt\n",
    "# For manipulating axis tick locations\n",
    "from matplotlib import ticker\n",
    "\n",
    "# An IPython magic syntax that tells matplotlib to plot in a new cell instead of a new window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a5a15",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Next, we will load the dataset with `pandas` as a DataFrane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654d692a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2222, 0.6250, 0.0678,  ..., 0.3750, 0.9322, 0.9583],\n",
       "        [0.1667, 0.4167, 0.0678,  ..., 0.5833, 0.9322, 0.9583],\n",
       "        [0.1111, 0.5000, 0.0508,  ..., 0.5000, 0.9492, 0.9583],\n",
       "        ...,\n",
       "        [0.6111, 0.4167, 0.7119,  ..., 0.5833, 0.2881, 0.2083],\n",
       "        [0.5278, 0.5833, 0.7458,  ..., 0.4167, 0.2542, 0.0833],\n",
       "        [0.4444, 0.4167, 0.6949,  ..., 0.5833, 0.3051, 0.2917]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Point to the local data file\n",
    "datafile = Path(\"iris\", \"iris.data\")\n",
    "# Read the data as a CSV, manually declaring the headers since the file doesn't have them\n",
    "data = pd.read_csv(datafile, names=[\"SL\", \"SW\", \"PL\", \"PW\", \"Label\"])\n",
    "\n",
    "# Intialize the scalar and update the values in-place to be normalized between [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "data[[\"SL\", \"SW\", \"PL\", \"PW\"]] = scaler.fit_transform(data[[\"SL\", \"SW\", \"PL\", \"PW\"]])\n",
    "\n",
    "# Complement code the data by pushing it into a Tensor\n",
    "data_cc = torch.Tensor(data[[\"SL\", \"SW\", \"PL\", \"PW\"]].values)\n",
    "# and appending the vector [1-x] along the feature dimension\n",
    "data_cc = torch.cat((data_cc, 1 - data_cc), dim=1)\n",
    "# What we get is a list of 8-dimensional samples\n",
    "data_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec870e2",
   "metadata": {},
   "source": [
    "Now that we have the data set up, we can infer the number of samples and data dimensions that we are working with.\n",
    "These two pieces of information will be useful for initializing the module and setting up the training loop.\n",
    "\n",
    "We have the luxury of knowing all of this information (and being able to know the exact bounds of the data) since the dataset is so small and completely available, but sometimes this info is not entirely clear.\n",
    "For now, we take advantage of this luxury with the normalization and complement coding above and the data dimension inference below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of samples is in the first dimensions of the complement-coded data\n",
    "n_samples = data_cc.shape[0]\n",
    "\n",
    "# The original dimension of the data is half of the complement coded dimension, which we make sure is cast back to an int\n",
    "dim = int(data_cc.shape[1] / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff9d6f",
   "metadata": {},
   "source": [
    "## Define AudeyART (FuzzyART) Module\n",
    "\n",
    "We will implement the FuzzyART module as a Python class containing all of the weights, hyperparamenters, and methods bundled together.\n",
    "The main interface that we want to the rest of the program is:\n",
    "\n",
    "1. `AudeyART(...)`: an intialization function where we pass whatever hyperparameters it will need.\n",
    "These hyperparameters will include what it needs to correctly setup the module structure, and it will also include the running variables such as learning rate, vigilance parameter, etc.\n",
    "2. `AudeyART.train(x: Tensor)`: to cluster the data, we will take in one sample at a time and train the model incrementally.\n",
    "Future work will take in an `x` and `y` in the supervised case.\n",
    "3. `AudeyART.classify(x: Tensor)`: once the model is trained, we need a function that gives predictions of what internal category the provided sample `x` belongs to.\n",
    "This will mainly be used to visualize the clustering results on the test split.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "Normally, proper docstrings would be used to document Python class functionality, but I am using inline comments to explain each line step-by-step instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class that contains everything we need\n",
    "class AudeyART():\n",
    "\n",
    "    # The constructor will be where we pass the hyperparameters necessary for the FuzzyART module to work.\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,           # The original dimension of the data\n",
    "        rho: float=0.6,     # The vigilance parameter in [0, 1]\n",
    "        beta: float=0.5,    # The learning rate in [0, 1]\n",
    "        alpha: float=0.001  # The choice parameter (close to zero)\n",
    "    ):\n",
    "        # The weights with be of shape [n_categories, 2 * n_dimensions] for complement coded samples\n",
    "        # NOTE: we start with weights of size [0, 8] with an uninitialized number of categories but known complement-coded dimension length\n",
    "        self.W = Tensor(size=[0, 2*dim])\n",
    "        # Keep track of the original dimension for later\n",
    "        self.dim = dim\n",
    "        # Save the rest of the operational hyperaparameters\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.rho = rho\n",
    "\n",
    "        return\n",
    "\n",
    "    # This function defines how we add a new category to the weight matrix\n",
    "    def grow(self, x: Tensor):\n",
    "        # This is a commented print statement for debugging the shapes of everything, kept here for reference\n",
    "        # print(self.W.shape, x.shape, x.reshape((1, self.dim*2)).shape)\n",
    "\n",
    "        # Growing the weight matrix ultimately means appending a new weight vector.\n",
    "        # This is slow how it is written because the memory is overwritten each time we add a new weight, but it works fine for small datasets.\n",
    "        self.W = torch.cat((self.W, x.reshape((1, self.dim*2))))\n",
    "\n",
    "        return\n",
    "\n",
    "    # This function defines what it means to initialize a new category and add it to the weight matrix\n",
    "    def init_cat(self, x:Tensor):\n",
    "        # First, we infer the existing number of categories\n",
    "        n_categories = self.W.shape[0]\n",
    "        # Next we initialize the \"uncommitted node\" with all ones\n",
    "        new_W = torch.ones(2*self.dim)\n",
    "        # We append the new node to the weights via our grow function\n",
    "        self.grow(new_W)\n",
    "        # Then we immediately update that category\n",
    "        # NOTE: Python is 0-indexed, so the n_categories we got before we appended a new one happens to be the correct index to update\n",
    "        self.learn(x, n_categories)\n",
    "\n",
    "        return\n",
    "\n",
    "    # This is the activation function to compute `T` given sample `x` and the weight at index `j`\n",
    "    def activation(self, x:Tensor, j:int):\n",
    "        # We will do this step-by-step to illustrate each computation.\n",
    "        # First, get the element-wise minimum (fuzzy intersection) of weight `j` and sample `x`.\n",
    "        xinw = torch.minimum(x, self.W[j, :])\n",
    "        # Taking the 1-norm is simply a sum\n",
    "        xinwnorm = torch.sum(xinw)\n",
    "        # We also need the 1-norm of the weight on its own\n",
    "        wnorm = torch.sum(self.W[j, :])\n",
    "        # We compute the activation as the norm of the fuzzy intersection over the weight norm plus the choice parameter (to not divide by zero).\n",
    "        Tj = xinwnorm / (self.alpha + wnorm)\n",
    "        # The output is then just this one activation `T` for weight `j`\n",
    "        return Tj\n",
    "\n",
    "    # This is the match function to compute `M` given sample `x` and the weight at index `j`\n",
    "    def match(self, x:Tensor, j:int):\n",
    "        # Again, the fuzzy intersection is just the elementwise-minimum between sample `x` and weight `j`\n",
    "        xinw = torch.minimum(x, self.W[j, :])\n",
    "        # The 1-norm is simply a sum of all elements\n",
    "        xinwnorm = torch.sum(xinw)\n",
    "        # The match is defined as fuzzy intersection over the 1-norm of the sample, but we know that the sample is normalized to [0, 1] and complement coded, so that term will always be equal to the original dimension number\n",
    "        Mj = xinwnorm / self.dim\n",
    "        # The output here is the match value for weight `j`\n",
    "        return Mj\n",
    "\n",
    "    # This function describes what it means to update a winning weight at index `j` with sample `x`\n",
    "    def learn(self, x:Tensor, j:int):\n",
    "        # We accidentally wrote the wrong learning function here first, so I am keeping it to show how the learning function (among others) can vary quite a bit between different ART modules\n",
    "        # self.W[j, :] = self.beta * x + (1-self.beta) * self.W[j, :]\n",
    "\n",
    "        # The FuzzyART weight update rule is a linear interpolation between the old weight and the fuzzy intersection, and how far along that interpolation we go is set by beta (between [0,1]).\n",
    "        self.W[j, :] = (1 - self.beta) * self.W[j, :] + self.beta * (torch.minimum(x, self.W[j, :]))\n",
    "\n",
    "        # Because we wrote this function to update the weight in place, we have an empty return\n",
    "        return\n",
    "\n",
    "    # This function is the main training interface, taking one sample at a time\n",
    "    def train(self, x:Tensor):\n",
    "        # First, we make sure that we have at least one category\n",
    "        n_categories = self.W.shape[0]\n",
    "        # If we don't have any categories, then immediately create one and update it\n",
    "        if n_categories == 0:\n",
    "            self.init_cat(x)\n",
    "            return\n",
    "\n",
    "        # Next, we compute the activations.\n",
    "        # NOTE: There are two ways to do this:\n",
    "        #   1. Preallocate a vector and iterate with a for loop\n",
    "        #   2. List comprehension, where this is done all at once\n",
    "        # List comprehension is sometimes slower for complicated low-level reasons, but it is a useful tool in lots of scenarios to make the syntax simpler.\n",
    "\n",
    "        # OPTION 1: For loop way (commented out for illustration purposes)\n",
    "        # T = torch.zeros(n_categories)\n",
    "        # for j in range(n_categories):\n",
    "        #     T[j] = self.activation(x, j)\n",
    "\n",
    "        # OPTION 2: List comprehension way\n",
    "        T = Tensor([self.activation(x, j) for j in range(n_categories)])\n",
    "\n",
    "        # Next, we do the vigilance check.\n",
    "        # This will involve going through the weights in order of highest activation and seeing if any of them pass the vigilance criterion.\n",
    "        # For FuzzyART, this simply means if `Mj > rho`, where `rho` is the vigilance parameter.\n",
    "        # The first one that passes this check wins and gets updated (hence winner-take-all).\n",
    "        # If none do, then a new category is created and updated (hence the neurogenesis).\n",
    "\n",
    "        # There are also two ways to handle the vigilance check programmatically:\n",
    "        #   1. Sort the activations then iterate\n",
    "        #   2. argmax the activations iteratively and zero them out if the don't pass.\n",
    "        # Both methods have pros and cons, but we will go with the sorting procedure since it is simpler (even though it is technically slower since the sort is O(n long(n)) )\n",
    "\n",
    "        # Sort the activations in order of highest activation first (in torch, this means descending order)\n",
    "        # NOTE: we want the resulting indices too because we care about the original weight index that was highest activated\n",
    "        T, inds = torch.sort(T, descending=True)\n",
    "\n",
    "        # Create a flag that acts as the signal if any weight won\n",
    "        did_match = False\n",
    "\n",
    "        # Iterate over the activations in order of highest first\n",
    "        for _, j in enumerate(T):\n",
    "            # Extract the index of the current node with a bunch of type casting (ints can be used to index in Python, but torch Tensors can't)\n",
    "            J = int(inds[int(j)])\n",
    "            # Compute the match value at that index\n",
    "            M = self.match(x, J)\n",
    "            # If the match value is greater than the vigilance parameter, update that weight and stop the search\n",
    "            if M > self.rho:\n",
    "                # Update the weight according to the FuzzyART learning rule\n",
    "                self.learn(x, J)\n",
    "                # Raise the flag to say that we did have a winner\n",
    "                did_match = True\n",
    "                # Stop iterating over the weights\n",
    "                break\n",
    "\n",
    "        # If we didnt' have a winner, then create a new weight entirely and immediately update it (similar to how we do if we create the first weight at the top)\n",
    "        if not did_match:\n",
    "            self.init_cat(x)\n",
    "\n",
    "        return\n",
    "\n",
    "    # This function will classify a provided sample and report the index of the internal category that it belongs to.\n",
    "    # NOTE: we also have a special option to get the \"best-matching-unit\" (bmu) in the case of complete mismatch (i.e., the sample was unrecognized), in which case we report the category that had the highest activation.\n",
    "    def classify(self, x:Tensor, get_bmu: bool = True):\n",
    "        # First, infer the number of categories that we currently have\n",
    "        n_categories = self.W.shape[0]\n",
    "\n",
    "        # Next compute the activations for each category using the list comprehension way\n",
    "        T = Tensor([self.activation(x, j) for j in range(n_categories)])\n",
    "\n",
    "        # Start out by saying that the reported value is mismatched, which we code with -1.\n",
    "        # This will be hopefully overwritten if we have a match\n",
    "        # NOTE: we initialize it out here because we want y_hat in this scope level so that it is correctly returned\n",
    "        y_hat = -1\n",
    "\n",
    "        # Sort the activations like before, keeping track of the corresponding indices\n",
    "        T, inds = torch.sort(T, descending=True)\n",
    "\n",
    "        # Have a match flag as before\n",
    "        did_match = False\n",
    "        # Iterate in order of highest activation\n",
    "        for _, j in enumerate(T):\n",
    "            # Extract the index of the corresponding weight\n",
    "            J = int(inds[int(j)])\n",
    "            # Compute the match function for the weight\n",
    "            M = self.match(x, J)\n",
    "            # If it satisfies the match criterion, report that category index as our winner\n",
    "            if M > self.rho:\n",
    "                # Set the output as that index and break out of the loop\n",
    "                y_hat = J\n",
    "                did_match = True\n",
    "                break\n",
    "\n",
    "        # If there was not a winner, we would should handle it appropriately\n",
    "        if not did_match:\n",
    "            # If we still want to report some actual value, return the highest activated category (which is first in the sorted list)\n",
    "            if get_bmu:\n",
    "                y_hat = int(inds[0])\n",
    "            # Otherwise, return a mismatch signal\n",
    "            else:\n",
    "                y_hat = -1\n",
    "\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5690f6",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We are now ready to train the model!\n",
    "\n",
    "In the unsupervised case, this means incrementally clustering the full dataset.\n",
    "For supervised learning scenarios, we would take a train/test split of the data to get an unbiased assessment of the testing accuracy, but in clustering we have no \"performance\" metric _per se_ (we just have the resulting partitioning).\n",
    "\n",
    "Therefore, we will first incrementally cluster (train) on the whole dataset, and then we will classify (do inference) on the whole dataset to see how the algorithm partitioned the data.\n",
    "\n",
    "Also, we will do this in one pass of the data (i.e., one epoch) to show how we can get a pretty good result even after seeing each piece of data only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aaab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First initialize the FuzzyART module with our selection of hyperparameters.\n",
    "# The dimension of the data is necessary, but the others are a matter of selection.\n",
    "# We will choose fast learning (beta=1.0) and a middle-of-the-road vigilance parameter (rho=0.6).\n",
    "aart = AudeyART(\n",
    "    dim,\n",
    "    rho=0.6,\n",
    "    beta=1.0\n",
    ")\n",
    "\n",
    "# To train, we loop over every sample\n",
    "for ix in range(n_samples):\n",
    "    # Extract the sample as a vector at sample index `ix`\n",
    "    data_x = data_cc[ix, :]\n",
    "\n",
    "    # Train the model on the sample!\n",
    "    # Because this is unsupervised, we have no other information to give to the model besides the sample itself.\n",
    "    aart.train(data_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d15c3",
   "metadata": {},
   "source": [
    "## Classify\n",
    "\n",
    "Hooray!\n",
    "We made and trained a FuzzyART module on the Iris dataset.\n",
    "But how did it do?\n",
    "\n",
    "One way we can inspect what it learned is by seeing how many categories were generated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0658587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 17\n",
      "Original number of samples: 150\n"
     ]
    }
   ],
   "source": [
    "# The lazy way is to just take the shape of the weight matrix and take the first dimension\n",
    "print(f\"Number of categories: {aart.W.shape[0]}\")\n",
    "print(f\"Original number of samples: {n_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211dfe7",
   "metadata": {},
   "source": [
    "Wowza, it worked!\n",
    "It is validating that we had fewer categories than we had samples, meaning that the algorithm bucketed the samples together.\n",
    "Let's get the full list of category labels for each sample to see how it did so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91585476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a simple Python vector for the label estimates (i.e., the category indices)\n",
    "y_hats = []\n",
    "# Iterate over all of the samples again\n",
    "for ix in range(n_samples):\n",
    "    # Extract the single sample as before\n",
    "    data_x = data_cc[ix, :]\n",
    "    # Classify the sample, this time getting the label that the FuzzyART algorithm prescribed to it\n",
    "    y_hat = aart.classify(data_x)\n",
    "    # Append to our list of labels\n",
    "    y_hats.append(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5de7a6",
   "metadata": {},
   "source": [
    "Now that we have the classifications, lets get an idea of the cluster sizes.\n",
    "One way to do that is to simply count the number of members in each cluster, which we can do by counting how many samples were assigned to each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5ba49ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's: 49\n",
      "Number of 1's: 1\n",
      "Number of 2's: 47\n",
      "Number of 3's: 1\n",
      "Number of 4's: 38\n",
      "Number of 5's: 1\n",
      "Number of 6's: 1\n",
      "Number of 7's: 1\n",
      "Number of 8's: 2\n",
      "Number of 9's: 1\n",
      "Number of 10's: 2\n",
      "Number of 11's: 1\n",
      "Number of 12's: 1\n",
      "Number of 13's: 1\n",
      "Number of 14's: 1\n",
      "Number of 15's: 1\n",
      "Number of 16's: 1\n"
     ]
    }
   ],
   "source": [
    "# The number of unique labels is the length of the list of labels.\n",
    "n_unique = len(set(y_hats))\n",
    "# Print the number of samples that got bucketed into that label\n",
    "for ix in range(n_unique):\n",
    "    print(f\"Number of {ix}'s: {y_hats.count(ix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e95f8b",
   "metadata": {},
   "source": [
    "Interesting!\n",
    "This type of behavior is common in clustering algorithms.\n",
    "A small subset of clusters got a lot of samples, and we ended up with a list of singleton clusters (i.e., a cluster with only one or a few samples belonging to them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e9b17",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We'd like to go one step further and actually see how the samples got clustered on a plot.\n",
    "Because the Iris dataset is 4-dimensional, we can't directly visualize the data on its own terms.\n",
    "We could take slices of the data where we look at two dimensions at a time, but that would generate a list of 4C2 (4 choose 2) = 6 plots, which is already a lot for a small set of features.\n",
    "Imagine if we were working with a dataset with way more features, like the number of pixels in an image!\n",
    "\n",
    "Instead, we will try to use a common technique called TSNE to project the data into two dimensions, trying to preserve the relative distances between points in the lower dimension as in the higher dimension.\n",
    "It's not perfect, but it gives us an idea of how the algorithm partitioned the data visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b21003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we make a couple of helper functions to set up the plot\n",
    "\n",
    "def add_2d_scatter(ax, points, colors, title=None):\n",
    "    x, y = points.T\n",
    "    ax.scatter(x, y, s=50, c=colors, alpha=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(ticker.NullFormatter())\n",
    "\n",
    "def plot_2d(points, colors, title):\n",
    "    fig, ax = plt.subplots(figsize=(3, 3), facecolor=\"white\", constrained_layout=True)\n",
    "    fig.suptitle(title, size=16)\n",
    "    add_2d_scatter(ax, points, colors)\n",
    "    plt.show()\n",
    "\n",
    "# Now, we initialize a TSNE module with its own set of hyperparameters for how it will be \"trained\" to create a mapping between the 4d data and its 2d projection.\n",
    "t_sne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,\n",
    "    init=\"random\",\n",
    "    max_iter=250,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "x = data[[\"SL\", \"SW\", \"PL\", \"PW\"]].values\n",
    "y = y_hats\n",
    "\n",
    "S_t_sne = t_sne.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "561cd191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('tab10')\n",
    "colors = [cmap(i) for i in y]\n",
    "plot_2d(S_t_sne, colors, \"T-distributed Stochastic  \\n Neighbor Embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7f628",
   "metadata": {},
   "source": [
    "## Scratch Workspace\n",
    "\n",
    "These cells just demonstrate some of the tinkering that we did to figure out how to do some crucial low-level stuff using Tensors.\n",
    "For example, we needed to find out how to append tensors along the right dimension, find the elementwise minimum between two Tensor vectors, and how to cast Tensor values between different types for correctly indexing into other arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465db1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(size=[0,2])\n",
    "b = torch.Tensor(np.array([[1, 1]]))\n",
    "# a.expand( )\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "c = torch.cat((a, b))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666c8489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3)\n",
    "b = torch.argmax(a)\n",
    "int(b.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audeyart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
