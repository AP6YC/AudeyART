{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b32343",
   "metadata": {},
   "source": [
    "# AudeyART\n",
    "\n",
    "This notebook implements a basic version of FuzzyART and tests it out on the relatively \"simple\" Iris dataset.\n",
    "\n",
    "FuzzyART is by default an unsupervised learning algorithm (a.k.a. clustering), so this file demonstrates how to cluster the Iris dataset with it.\n",
    "Future experiments and scripts will show how to do so in a supervised way so that train/test accuracy can be computed.\n",
    "\n",
    "For now, we will see if a \"standard\" FuzzyART module can identify some natural structures/clusters in the Iris data without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85dd347",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "First, we load all of our dependencies for the notebook.\n",
    "Be sure to be working in an activated virtual environment with the requirements installed with\n",
    "\n",
    "```shell\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "More about this in the <a href=README.md> <tt>README.md</tt></a> file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STDLIB IMPORTS\n",
    "\n",
    "# For manipulating local paths in an object-oriented way\n",
    "from pathlib import Path\n",
    "\n",
    "# 3RD PARTY IMPORTS\n",
    "\n",
    "# The PyTorch library containing neural network utilities and the Tensor datatype\n",
    "import torch\n",
    "# A convenient import of Tensor so that we don't have to write torch.Tensor every time\n",
    "from torch import Tensor\n",
    "# Pandas for loading and manipulating data as a DataFrame\n",
    "import pandas as pd\n",
    "# Numpy for handling numpy arrays (i.e., matplotlib doesn't understand Tensor types, but it does know numpy.nparray)\n",
    "import numpy as np\n",
    "# A sklearn utility for handling normalization of data automatically\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# From scikit-learn, for casting the data to 2D for visualization.\n",
    "# This is not how the data actually looks in 4D, but the best that we can do is to cast it to 2D such that relative distances are mostly maintained.\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# The most common way of importing matplotlib for plotting in Python\n",
    "from matplotlib import pyplot as plt\n",
    "# For manipulating axis tick locations\n",
    "from matplotlib import ticker\n",
    "\n",
    "# An IPython magic syntax that tells matplotlib to plot in a new cell instead of a new window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a5a15",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Next, we will load the dataset with `pandas` as a DataFrane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654d692a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2222, 0.6250, 0.0678,  ..., 0.3750, 0.9322, 0.9583],\n",
       "        [0.1667, 0.4167, 0.0678,  ..., 0.5833, 0.9322, 0.9583],\n",
       "        [0.1111, 0.5000, 0.0508,  ..., 0.5000, 0.9492, 0.9583],\n",
       "        ...,\n",
       "        [0.6111, 0.4167, 0.7119,  ..., 0.5833, 0.2881, 0.2083],\n",
       "        [0.5278, 0.5833, 0.7458,  ..., 0.4167, 0.2542, 0.0833],\n",
       "        [0.4444, 0.4167, 0.6949,  ..., 0.5833, 0.3051, 0.2917]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Point to the local data file\n",
    "datafile = Path(\"iris\", \"iris.data\")\n",
    "# Read the data as a CSV, manually declaring the headers since the file doesn't have them\n",
    "data = pd.read_csv(datafile, names=[\"SL\", \"SW\", \"PL\", \"PW\", \"Label\"])\n",
    "\n",
    "# Intialize the scalar and update the values in-place to be normalized between [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "data[[\"SL\", \"SW\", \"PL\", \"PW\"]] = scaler.fit_transform(data[[\"SL\", \"SW\", \"PL\", \"PW\"]])\n",
    "\n",
    "# Complement code the data by pushing it into a Tensor\n",
    "data_cc = torch.Tensor(data[[\"SL\", \"SW\", \"PL\", \"PW\"]].values)\n",
    "# and appending the vector [1-x] along the feature dimension\n",
    "data_cc = torch.cat((data_cc, 1 - data_cc), dim=1)\n",
    "# What we get is a list of 8-dimensional samples\n",
    "data_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff9d6f",
   "metadata": {},
   "source": [
    "## Define AudeyART (FuzzyART) Module\n",
    "\n",
    "We will implement the FuzzyART module as a Python class containing all of the weights, hyperparamenters, and methods bundled together.\n",
    "The main interface that we want to the rest of the program is:\n",
    "\n",
    "1. `AudeyART(...)`: an intialization function where we pass whatever hyperparameters it will need.\n",
    "These hyperparameters will include what it needs to correctly setup the module structure, and it will also include the running variables such as learning rate, vigilance parameter, etc.\n",
    "2. `AudeyART.train(x: Tensor)`: to cluster the data, we will take in one sample at a time and train the model incrementally.\n",
    "Future work will take in an `x` and `y` in the supervised case.\n",
    "3. `AudeyART.classify(x: Tensor)`: once the model is trained, we need a function that gives predictions of what internal category the provided sample `x` belongs to.\n",
    "This will mainly be used to visualize the clustering results on the test split.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b>\n",
    "Normally, proper docstrings would be used to document Python class functionality, but I am using inline comments to explain each line step-by-step instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class that contains everything we need\n",
    "class AudeyART():\n",
    "\n",
    "    # The constructor will be where we pass the hyperparameters necessary for the FuzzyART module to work.\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,           # The original dimension of the data\n",
    "        rho: float=0.6,     # The vigilance parameter in [0, 1]\n",
    "        beta: float=0.5,    # The learning rate in [0, 1]\n",
    "        alpha: float=0.001  # The choice parameter (close to zero)\n",
    "    ):\n",
    "        # The weights with be of shape [n_categories, 2 * n_dimensions] for complement coded samples\n",
    "        # NOTE: we start with weights of size [0, 8] with an uninitialized number of categories but known complement-coded dimension length\n",
    "        self.W = Tensor(size=[0, 2*dim])\n",
    "        # Keep track of the original dimension for later\n",
    "        self.dim = dim\n",
    "        # Save the rest of the operational hyperaparameters\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.rho = rho\n",
    "\n",
    "        return\n",
    "\n",
    "    # This function defines how we add a new category to the weight matrix\n",
    "    def grow(self, x: Tensor):\n",
    "        # This is a commented print statement for debugging the shapes of everything, kept here for reference\n",
    "        # print(self.W.shape, x.shape, x.reshape((1, self.dim*2)).shape)\n",
    "\n",
    "        # Growing the weight matrix ultimately means appending a new weight vector.\n",
    "        # This is slow how it is written because the memory is overwritten each time we add a new weight, but it works fine for small datasets.\n",
    "        self.W = torch.cat((self.W, x.reshape((1, self.dim*2))))\n",
    "\n",
    "        return\n",
    "\n",
    "    # This function defines what it means to initialize a new category and add it to the weight matrix\n",
    "    def init_cat(self, x:Tensor):\n",
    "        # First, we infer the existing number of categories\n",
    "        n_categories = self.W.shape[0]\n",
    "        # Next we initialize the \"uncommitted node\" with all ones\n",
    "        new_W = torch.ones(2*self.dim)\n",
    "        # We append the new node to the weights via our grow function\n",
    "        self.grow(new_W)\n",
    "        # Then we immediately update that category\n",
    "        # NOTE: Python is 0-indexed, so the n_categories we got before we appended a new one happens to be the correct index to update\n",
    "        self.learn(x, n_categories)\n",
    "\n",
    "        return\n",
    "\n",
    "    # This is the activation function to compute `T` given sample `x` and the weight at index `j`\n",
    "    def activation(self, x:Tensor, j:int):\n",
    "        # We will do this step-by-step to illustrate each computation.\n",
    "        # First, get the element-wise minimum (fuzzy intersection) of weight `j` and sample `x`.\n",
    "        xinw = torch.minimum(x, self.W[j, :])\n",
    "        # Taking the 1-norm is simply a sum\n",
    "        xinwnorm = torch.sum(xinw)\n",
    "        # We also need the 1-norm of the weight on its own\n",
    "        wnorm = torch.sum(self.W[j, :])\n",
    "        # We compute the activation as the norm of the fuzzy intersection over the weight norm plus the choice parameter (to not divide by zero).\n",
    "        Tj = xinwnorm / (self.alpha + wnorm)\n",
    "        # The output is then just this one activation `T` for weight `j`\n",
    "        return Tj\n",
    "\n",
    "    # This is the match function to compute `M` given sample `x` and the weight at index `j`\n",
    "    def match(self, x:Tensor, j:int):\n",
    "        # Again, the fuzzy intersection is just the elementwise-minimum between sample `x` and weight `j`\n",
    "        xinw = torch.minimum(x, self.W[j, :])\n",
    "        # The 1-norm is simply a sum of all elements\n",
    "        xinwnorm = torch.sum(xinw)\n",
    "        # The match is defined as fuzzy intersection over the 1-norm of the sample, but we know that the sample is normalized to [0, 1] and complement coded, so that term will always be equal to the original dimension number\n",
    "        Mj = xinwnorm / self.dim\n",
    "        # The output here is the match value for weight `j`\n",
    "        return Mj\n",
    "\n",
    "    # This function describes what it means to update a winning weight at index `j` with sample `x`\n",
    "    def learn(self, x:Tensor, j:int):\n",
    "        # We accidentally wrote the wrong learning function here first, so I am keeping it to show how the learning function (among others) can vary quite a bit between different ART modules\n",
    "        # self.W[j, :] = self.beta * x + (1-self.beta) * self.W[j, :]\n",
    "\n",
    "        # The FuzzyART weight update rule is a linear interpolation between the old weight and the fuzzy intersection, and how far along that interpolation we go is set by beta (between [0,1]).\n",
    "        self.W[j, :] = (1 - self.beta) * self.W[j, :] + self.beta * (torch.minimum(x, self.W[j, :]))\n",
    "\n",
    "        # Because we wrote this function to update the weight in place, we have an empty return\n",
    "        return\n",
    "\n",
    "    # This function is the main training interface, taking one sample at a time\n",
    "    def train(self, x:Tensor):\n",
    "        # First, we make sure that we have at least one category\n",
    "        n_categories = self.W.shape[0]\n",
    "        # If we don't have any categories, then immediately create one and update it\n",
    "        if n_categories == 0:\n",
    "            self.init_cat(x)\n",
    "            return\n",
    "\n",
    "        # Next, we compute the activations.\n",
    "        # NOTE: There are two ways to do this:\n",
    "        #   1. Preallocate a vector and iterate with a for loop\n",
    "        #   2. List comprehension, where this is done all at once\n",
    "        # List comprehension is sometimes slower for complicated low-level reasons, but it is a useful tool in lots of scenarios to make the syntax simpler.\n",
    "\n",
    "        # OPTION 1: For loop way (commented out for illustration purposes)\n",
    "        # T = torch.zeros(n_categories)\n",
    "        # for j in range(n_categories):\n",
    "        #     T[j] = self.activation(x, j)\n",
    "\n",
    "        # OPTION 2: List comprehension way\n",
    "        T = Tensor([self.activation(x, j) for j in range(n_categories)])\n",
    "\n",
    "        # Next, we do the vigilance check.\n",
    "        # This will involve going through the weights in order of highest activation and seeing if any of them pass the vigilance criterion.\n",
    "        # For FuzzyART, this simply means if `Mj > rho`, where `rho` is the vigilance parameter.\n",
    "        # The first one that passes this check wins and gets updated (hence winner-take-all).\n",
    "        # If none do, then a new category is created and updated (hence the neurogenesis).\n",
    "\n",
    "        # There are also two ways to handle the vigilance check programmatically:\n",
    "        #   1. Sort the activations then iterate\n",
    "        #   2. argmax the activations iteratively and zero them out if the don't pass.\n",
    "        # Both methods have pros and cons, but we will go with the sorting procedure since it is simpler (even though it is technically slower since the sort is O(n long(n)) )\n",
    "\n",
    "        # Sort the activations in order of highest activation first (in torch, this means descending order)\n",
    "        # NOTE: we want the resulting indices too because we care about the original weight index that was highest activated\n",
    "        T, inds = torch.sort(T, descending=True)\n",
    "        # Create a flag that acts as the signal if any weight won\n",
    "        did_match = False\n",
    "        # Iterate over the activations in order of highest first\n",
    "        for _, j in enumerate(T):\n",
    "            # Extract the index of the current node with a bunch of type casting (ints can be used to index in Python, but torch Tensors can't)\n",
    "            J = int(inds[int(j)])\n",
    "            # Compute the match value at that index\n",
    "            M = self.match(x, J)\n",
    "            # If the match value is greater than the vigilance parameter, update that weight and stop the search\n",
    "            if M > self.rho:\n",
    "                # Update the weight according to the FuzzyART learning rule\n",
    "                self.learn(x, J)\n",
    "                # Raise the flag to say that we did have a winner\n",
    "                did_match = True\n",
    "                # Stop iterating over the weights\n",
    "                break\n",
    "\n",
    "        # If we didnt' have a winner, then create a new weight entirely and immediately update it (similar to how we do if we create the first weight at the top)\n",
    "        if not did_match:\n",
    "            self.init_cat(x)\n",
    "\n",
    "        return\n",
    "\n",
    "    def classify(self, x:Tensor, get_bmu = True):\n",
    "        n_categories = self.W.shape[0]\n",
    "\n",
    "        # List comprehension way\n",
    "        T = Tensor([self.activation(x, j) for j in range(n_categories)])\n",
    "\n",
    "        y_hat = -1\n",
    "\n",
    "        T, inds = torch.sort(T, descending=True)\n",
    "        did_match = False\n",
    "        # while not did_match:\n",
    "        for _, j in enumerate(T):\n",
    "            # J = int(torch.argmax(T).data)\n",
    "            J = int(inds[int(j)])\n",
    "            M = self.match(x, J)\n",
    "            if M > self.rho:\n",
    "                y_hat = J\n",
    "                did_match = True\n",
    "                break\n",
    "\n",
    "        if not did_match:\n",
    "            if not get_bmu:\n",
    "                y_hat = -1\n",
    "            else:\n",
    "                y_hat = int(inds[0])\n",
    "\n",
    "        return y_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666c8489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3)\n",
    "b = torch.argmax(a)\n",
    "int(b.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5690f6",
   "metadata": {},
   "source": [
    "## Init Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad138e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer data dimensions\n",
    "n_samples = data_cc.shape[0]\n",
    "dim = int(data_cc.shape[1] / 2)\n",
    "\n",
    "# Init FuzzyART module\n",
    "# aart = AudeyART(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbc48d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2aaab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over every sample\n",
    "aart = AudeyART(dim, rho=0.6, beta=1.0)\n",
    "for ix in range(n_samples):\n",
    "    data_x = data_cc[ix, :]\n",
    "    aart.train(data_x)\n",
    "    # print(data_x)\n",
    "\n",
    "y_hats = []\n",
    "for ix in range(n_samples):\n",
    "    data_x = data_cc[ix, :]\n",
    "    y_hat = aart.classify(data_x)\n",
    "    y_hats.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b21003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_2d_scatter(ax, points, colors, title=None):\n",
    "    x, y = points.T\n",
    "    ax.scatter(x, y, s=50, c=colors, alpha=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(ticker.NullFormatter())\n",
    "\n",
    "def plot_2d(points, colors, title):\n",
    "    fig, ax = plt.subplots(figsize=(3, 3), facecolor=\"white\", constrained_layout=True)\n",
    "    fig.suptitle(title, size=16)\n",
    "    add_2d_scatter(ax, points, colors)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "t_sne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,\n",
    "    init=\"random\",\n",
    "    max_iter=250,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "# x, y = get_points(model, test_loader)\n",
    "\n",
    "x = data_cc.numpy()\n",
    "y = y_hats\n",
    "\n",
    "S_t_sne = t_sne.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "561cd191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('tab10')\n",
    "colors = [cmap(i) for i in y]\n",
    "plot_2d(S_t_sne, colors, \"T-distributed Stochastic  \\n Neighbor Embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465db1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(size=[0,2])\n",
    "b = torch.Tensor(np.array([[1, 1]]))\n",
    "# a.expand( )\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "c = torch.cat((a, b))\n",
    "c.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audeyart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
